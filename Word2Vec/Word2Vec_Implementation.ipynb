{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QNENZ6G02Esl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample corpus\n",
        "corpus = [\n",
        "    \"the quick brown fox jumps over the lazy dog\",\n",
        "    \"the fox is quick and the dog is lazy\",\n",
        "    \"the dog and the fox are friends\"\n",
        "]"
      ],
      "metadata": {
        "id": "u3sduCGk2vg6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize corpus\n",
        "words = set(\" \".join(corpus).split())\n",
        "word2idx = {word: i for i, word in enumerate(words)}\n",
        "idx2word = {i: word for word, i in word2idx.items()}\n",
        "vocab_size = len(words)"
      ],
      "metadata": {
        "id": "WyOTYb4y20bS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQNNKZK-21EB",
        "outputId": "aecd9c5c-6a35-4a79-e69e-db3ebe3b351d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EMBEDDING_DIM = 10\n",
        "CONTEXT_SIZE = 2\n",
        "EPOCHS = 100\n",
        "LR = 0.01"
      ],
      "metadata": {
        "id": "1sHWyENt2_TQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cbow_data(corpus,context_size=2):\n",
        "    data = []\n",
        "    for sentence in corpus:\n",
        "        tokens = sentence.split()\n",
        "        for i in range(context_size, len(tokens) - context_size):\n",
        "            context = [tokens[j] for j in range(i - context_size, i + context_size + 1) if j != i]\n",
        "            target = tokens[i]\n",
        "            data.append((context, target))\n",
        "    return data"
      ],
      "metadata": {
        "id": "mnpudjeC3FO4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_data = generate_cbow_data(corpus, CONTEXT_SIZE)\n",
        "cbow_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLIY2URX3qQD",
        "outputId": "88f3296f-3606-475a-d47a-230ce4ba2f48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['the', 'quick', 'fox', 'jumps'], 'brown'),\n",
              " (['quick', 'brown', 'jumps', 'over'], 'fox'),\n",
              " (['brown', 'fox', 'over', 'the'], 'jumps'),\n",
              " (['fox', 'jumps', 'the', 'lazy'], 'over'),\n",
              " (['jumps', 'over', 'lazy', 'dog'], 'the'),\n",
              " (['the', 'fox', 'quick', 'and'], 'is'),\n",
              " (['fox', 'is', 'and', 'the'], 'quick'),\n",
              " (['is', 'quick', 'the', 'dog'], 'and'),\n",
              " (['quick', 'and', 'dog', 'is'], 'the'),\n",
              " (['and', 'the', 'is', 'lazy'], 'dog'),\n",
              " (['the', 'dog', 'the', 'fox'], 'and'),\n",
              " (['dog', 'and', 'fox', 'are'], 'the'),\n",
              " (['and', 'the', 'are', 'friends'], 'fox')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_skipgram_data(corpus, context_size=2):\n",
        "    data = []\n",
        "    for sentence in corpus:\n",
        "        tokens = sentence.split()\n",
        "        for i in range(context_size, len(tokens) - context_size):\n",
        "            target = tokens[i]\n",
        "            for j in range(i - context_size, i + context_size + 1):\n",
        "                if j != i:\n",
        "                    data.append((target, tokens[j]))\n",
        "    return data"
      ],
      "metadata": {
        "id": "Dka7jBwG37I8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram_data = generate_skipgram_data(corpus, CONTEXT_SIZE)\n",
        "skipgram_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF32WHEC39Ov",
        "outputId": "f3c04d6b-215b-43e8-847f-34d4899e12c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('brown', 'the'),\n",
              " ('brown', 'quick'),\n",
              " ('brown', 'fox'),\n",
              " ('brown', 'jumps'),\n",
              " ('fox', 'quick'),\n",
              " ('fox', 'brown'),\n",
              " ('fox', 'jumps'),\n",
              " ('fox', 'over'),\n",
              " ('jumps', 'brown'),\n",
              " ('jumps', 'fox'),\n",
              " ('jumps', 'over'),\n",
              " ('jumps', 'the'),\n",
              " ('over', 'fox'),\n",
              " ('over', 'jumps'),\n",
              " ('over', 'the'),\n",
              " ('over', 'lazy'),\n",
              " ('the', 'jumps'),\n",
              " ('the', 'over'),\n",
              " ('the', 'lazy'),\n",
              " ('the', 'dog'),\n",
              " ('is', 'the'),\n",
              " ('is', 'fox'),\n",
              " ('is', 'quick'),\n",
              " ('is', 'and'),\n",
              " ('quick', 'fox'),\n",
              " ('quick', 'is'),\n",
              " ('quick', 'and'),\n",
              " ('quick', 'the'),\n",
              " ('and', 'is'),\n",
              " ('and', 'quick'),\n",
              " ('and', 'the'),\n",
              " ('and', 'dog'),\n",
              " ('the', 'quick'),\n",
              " ('the', 'and'),\n",
              " ('the', 'dog'),\n",
              " ('the', 'is'),\n",
              " ('dog', 'and'),\n",
              " ('dog', 'the'),\n",
              " ('dog', 'is'),\n",
              " ('dog', 'lazy'),\n",
              " ('and', 'the'),\n",
              " ('and', 'dog'),\n",
              " ('and', 'the'),\n",
              " ('and', 'fox'),\n",
              " ('the', 'dog'),\n",
              " ('the', 'and'),\n",
              " ('the', 'fox'),\n",
              " ('the', 'are'),\n",
              " ('fox', 'and'),\n",
              " ('fox', 'the'),\n",
              " ('fox', 'are'),\n",
              " ('fox', 'friends')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self,vocab_size,embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self,context_words):\n",
        "        embeds = self.embeddings(context_words) # (batch_size, context_size, embedding_dim)\n",
        "        h = embeds.mean(dim=1)  # Averaging embeddings\n",
        "        out = self.linear(h)  # Output layer\n",
        "        return out"
      ],
      "metadata": {
        "id": "smhEM9E64BRU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_model = CBOW(vocab_size, EMBEDDING_DIM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cbow_model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "whsY3IXX5F2X"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for context,target in cbow_data:\n",
        "        context_indices = torch.tensor([word2idx[word] for word in context])\n",
        "        target_index = torch.tensor([word2idx[target]])\n",
        "        optimizer.zero_grad()\n",
        "        output = cbow_model(context_indices.unsqueeze(0))\n",
        "        loss = criterion(output, target_index)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {total_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K65ORlYv5Kpd",
        "outputId": "a653bec2-9a38-4c25-ffd5-ed256fde92fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 32.8300\n",
            "Epoch 10, Loss: 14.1051\n",
            "Epoch 20, Loss: 5.3889\n",
            "Epoch 30, Loss: 2.1940\n",
            "Epoch 40, Loss: 1.0703\n",
            "Epoch 50, Loss: 0.6160\n",
            "Epoch 60, Loss: 0.3970\n",
            "Epoch 70, Loss: 0.2762\n",
            "Epoch 80, Loss: 0.2027\n",
            "Epoch 90, Loss: 0.1547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, target_word):\n",
        "        embed = self.embeddings(target_word)  # (batch_size, embedding_dim)\n",
        "        out = self.linear(embed)  # Output layer\n",
        "        return out"
      ],
      "metadata": {
        "id": "ufVvVgxr5j_A"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram_model = SkipGram(vocab_size, EMBEDDING_DIM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(skipgram_model.parameters(), lr=LR)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for target, context in skipgram_data:\n",
        "        target_index = torch.tensor([word2idx[target]])\n",
        "        context_index = torch.tensor([word2idx[context]])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = skipgram_model(target_index)\n",
        "        loss = criterion(output, context_index)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {total_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJzbceu85pCp",
        "outputId": "84ff0862-4717-4936-9acc-45714e1fd35e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 137.0931\n",
            "Epoch 10, Loss: 96.5822\n",
            "Epoch 20, Loss: 93.0257\n",
            "Epoch 30, Loss: 92.0243\n",
            "Epoch 40, Loss: 91.5886\n",
            "Epoch 50, Loss: 91.3385\n",
            "Epoch 60, Loss: 91.1720\n",
            "Epoch 70, Loss: 91.0509\n",
            "Epoch 80, Loss: 90.9574\n",
            "Epoch 90, Loss: 90.8822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def get_word_embedding(model, word):\n",
        "    \"\"\"Retrieve the embedding vector for a given word.\"\"\"\n",
        "    word_idx = torch.tensor([word2idx[word]])\n",
        "    embedding = model.embeddings(word_idx)\n",
        "    return embedding.detach().numpy().squeeze()  # Convert tensor to numpy array\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Compute the cosine similarity between two vectors.\"\"\"\n",
        "    vec1 = torch.tensor(vec1)\n",
        "    vec2 = torch.tensor(vec2)\n",
        "    similarity = F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0))\n",
        "    return similarity.item()"
      ],
      "metadata": {
        "id": "OLjugf9a556q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar(model, target_word, top_n=5):\n",
        "    \"\"\"Find the most similar words to the given target word based on cosine similarity.\"\"\"\n",
        "    target_embedding = get_word_embedding(model, target_word)\n",
        "    similarities = []\n",
        "\n",
        "    for word in words:  # Iterate over all words in the vocabulary\n",
        "        if word == target_word:\n",
        "            continue\n",
        "        word_embedding = get_word_embedding(model, word)\n",
        "        similarity = cosine_similarity(target_embedding, word_embedding)\n",
        "        similarities.append((word, similarity))\n",
        "\n",
        "    # Sort by similarity score in descending order\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:top_n]"
      ],
      "metadata": {
        "id": "j6Tgb9RT5-Ni"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Most similar words to 'fox' using CBOW:\")\n",
        "print(most_similar(cbow_model, \"fox\"))\n",
        "\n",
        "# Test with Skip-gram model\n",
        "print(\"\\nMost similar words to 'fox' using Skip-gram:\")\n",
        "print(most_similar(skipgram_model, \"fox\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFxkQpA-6DfU",
        "outputId": "7d3b66a3-e1b0-4655-d2f3-27d47bd7a717"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most similar words to 'fox' using CBOW:\n",
            "[('quick', 0.23087164759635925), ('the', 0.04092662036418915), ('jumps', 0.01653880998492241), ('are', -0.11102814227342606), ('dog', -0.13629382848739624)]\n",
            "\n",
            "Most similar words to 'fox' using Skip-gram:\n",
            "[('is', 0.3401443660259247), ('lazy', 0.2606309652328491), ('brown', -0.05256767198443413), ('over', -0.05700305849313736), ('jumps', -0.08019979298114777)]\n"
          ]
        }
      ]
    }
  ]
}